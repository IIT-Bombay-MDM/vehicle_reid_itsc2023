{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1757029,"sourceType":"datasetVersion","datasetId":1044287}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Check GPU Access","metadata":{}},{"cell_type":"code","source":"import locale\nlocale.getpreferredencoding = lambda x: \"UTF-8\"\n\n!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install torch torchvision opencv-python matplotlib ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom PIL import Image\nfrom ultralytics import YOLO\nfrom torchvision.models.detection.retinanet import RetinaNet_ResNet50_FPN_Weights\nfrom torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n\n\ndef load_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    transform = transforms.Compose([\n        transforms.ToTensor()\n    ])\n    return transform(image).unsqueeze(0)\n\n\ndef load_yolov9_model():\n    model = YOLO('yolov9c.pt')\n    return model\n\n\ndef load_fasterrcnn_model():\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n    model.eval()\n    return model\n\n\ndef load_retinanet_model():\n    model = torchvision.models.detection.retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT)\n    model.eval()\n    return model\n\n\ndef run_yolov9(model, image):\n    results = model.predict(image)\n    boxes = results[0].boxes\n    if boxes is not None:\n        box_coords = boxes.xyxy\n    else:\n        box_coords = None\n    return box_coords\n\n\ndef run_fasterrcnn(model, image, boxes):\n    refined_boxes = []\n    refined_labels = []\n    refined_scores = []\n\n    image = image.squeeze(0)\n\n    for box in boxes:\n        x1, y1, x2, y2 = map(int, box.tolist())\n\n        cropped_image = image[:, y1:y2, x1:x2].unsqueeze(0)\n        outputs = model([cropped_image])\n\n        refined_boxes.append(outputs[0][\"boxes\"])\n        refined_labels.append(outputs[0][\"labels\"])\n        refined_scores.append(outputs[0][\"scores\"])\n\n    return torch.cat(refined_boxes), torch.cat(refined_labels), torch.cat(refined_scores)\n\n\ndef run_retinanet(model, image, boxes):\n    refined_boxes = []\n    refined_labels = []\n    refined_scores = []\n\n    image = image.squeeze(0)\n\n    for box in boxes:\n        x1, y1, x2, y2 = map(int, box.tolist())\n\n        cropped_image = image[:, y1:y2, x1:x2].unsqueeze(0)\n        outputs = model([cropped_image])\n\n        refined_boxes.append(outputs[0][\"boxes\"])\n        refined_labels.append(outputs[0][\"labels\"])\n        refined_scores.append(outputs[0][\"scores\"])\n\n    return torch.cat(refined_boxes), torch.cat(refined_labels), torch.cat(refined_scores)\n\n\ndef plot_image_with_boxes(image, boxes, title=\"Detected Objects\"):\n    img = np.array(image.permute(1, 2, 0).cpu().numpy())\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n    for box in boxes:\n        x1, y1, x2, y2 = map(int, box)\n        img = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\n    plt.figure(figsize=(10, 10))\n    plt.title(title)\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()\n\n\ndef ensemble_detection(image_path):\n    image = load_image(image_path)\n\n    # YOLO for initial detection\n    yolo_model = load_yolov9_model()\n    yolo_boxes = run_yolov9(yolo_model, image)\n    print(\"YOLOv9 detected boxes:\", yolo_boxes)\n    plot_image_with_boxes(image.squeeze(0), yolo_boxes, \"YOLOv9 Detections\")\n\n    # Faster R-CNN for bounding box refinement\n    fasterrcnn_model = load_fasterrcnn_model()\n    faster_boxes, faster_labels, faster_scores = run_fasterrcnn(fasterrcnn_model, image, yolo_boxes)\n    print(\"Faster R-CNN refined boxes:\", faster_boxes)\n    plot_image_with_boxes(image.squeeze(0), faster_boxes, \"Faster R-CNN Detections\")\n\n    # RetinaNet for final refinement and detection of smaller objects\n    retinanet_model = load_retinanet_model()\n    retinanet_boxes, retinanet_labels, retinanet_scores = run_retinanet(retinanet_model, image, faster_boxes)\n    print(\"RetinaNet refined boxes:\", retinanet_boxes)\n    plot_image_with_boxes(image.squeeze(0), retinanet_boxes, \"RetinaNet Detections\")\n\n\nimage_path = \"/kaggle/input/vehicle-detection-8-classes-object-detection/train/images/Highway_1007_2020-07-30_jpg.rf.b97b7d182ed136840b68dc1680a76610.jpg\"\nensemble_detection(image_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}